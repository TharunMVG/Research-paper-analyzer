{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "74js4HVnRdbp",
        "outputId": "3a9ed845-68df-43e5-9ea5-77325c7b084b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika, sgmllib3k\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=60264b1a5f47ced2183652d8a367af726be5ce2b47e07d2b69fd198a55115035\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=29b30d70cfbb2c81a0549b940f02167e23625fab09ae24856f7a1e9afe54bfa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built pypika sgmllib3k\n",
            "Installing collected packages: sgmllib3k, pypika, monotonic, filetype, durationpy, uvloop, uvicorn, python-dotenv, pytesseract, pyproject_hooks, pdf2image, overrides, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, feedparser, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, build, arxiv, pydantic-settings, onnxruntime, kubernetes, fastapi, dataclasses-json, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, google-ai-generativelanguage, opentelemetry-instrumentation-fastapi, langchain-google-genai, langchain, langchain-community, chromadb\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.23\n",
            "    Uninstalling langchain-0.3.23:\n",
            "      Successfully uninstalled langchain-0.3.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arxiv-2.2.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.6 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.9 feedparser-6.0.11 filetype-1.2.0 google-ai-generativelanguage-0.6.17 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-32.0.1 langchain-0.3.24 langchain-community-0.3.22 langchain-core-0.3.55 langchain-google-genai-2.1.3 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.1.0 onnxruntime-1.21.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-util-http-0.53b1 overrides-7.7.0 pdf2image-1.17.0 posthog-3.25.0 pydantic-settings-2.9.1 pypika-0.48.9 pyproject_hooks-1.2.0 pytesseract-0.3.13 python-dotenv-1.1.0 sgmllib3k-1.0.0 starlette-0.45.3 typing-inspect-0.9.0 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7d75c47e14d44c779a1745325ae2b643",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, bitsandbytes, trl\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 trl-0.16.1 xxhash-3.5.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,604 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,845 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,839 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,266 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,696 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,111 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,150 kB]\n",
            "Fetched 29.0 MB in 3s (9,971 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.7 [186 kB]\n",
            "Fetched 186 kB in 1s (217 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126333 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.7_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install arxiv langchain langchain-google-genai langchain-community spacy nltk chromadb pdf2image pytesseract pillow\n",
        "!pip install sentence-transformers networkx scikit-learn matplotlib spacy\n",
        "!pip install torch transformers peft datasets bitsandbytes trl\n",
        "!apt-get update\n",
        "!apt-get install -y poppler-utils tesseract-ocr\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LFEhTiyny_J",
        "outputId": "5e68bd2d-4c9d-4e6f-86c5-09d48e4f7fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "!pip install spacy sentence-transformers scikit-learn networkx matplotlib\n",
        "!python -m spacy download en_core_web_md\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "034b0dc919df4f7cb046f148d7f367ba",
            "c166d072bac549af9a671d1727f06175",
            "a646a9439bd34604a60f458a8220abf7",
            "0d4002cd0cd5469aa6e48c151d82db9e",
            "90c4963b468446f1ba41b97b46f5663c",
            "ff792a0b55e64ea0b5b91c618bed4bc8",
            "6954435b1acf455f9a60a8adfba333e0",
            "b50f7118303145bea7f13a4a30b8d302",
            "ecd1e4183fe84006a2f0f1ff7278581f",
            "f8d1900d3fda42b88d4a14bd4496da79",
            "b294e6d1213f43788a043e9f77c1319b"
          ]
        },
        "id": "4oGWiXvGdexU",
        "outputId": "6be709c6-296f-4676-f7bf-898715548167"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/content/prompt_engineering.py:17: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "034b0dc919df4f7cb046f148d7f367ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error initializing model: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 72.12 MiB is free. Process 222348 has 14.67 GiB memory in use. Of the allocated memory 14.17 GiB is allocated by PyTorch, and 396.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Falling back to a smaller model...\n",
            "Welcome to the Multimodal Research Paper Analyzer!\n",
            "This tool supports text and PDF inputs.\n",
            "\n",
            "\n",
            "Select input type: 1. Text, 2. PDF\n",
            "Please upload a PDF of a research paper.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45a18070-5bb0-4468-b38d-3b8ea14ae06c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45a18070-5bb0-4468-b38d-3b8ea14ae06c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving sample_paper.pdf to sample_paper (1).pdf\n",
            "\n",
            "Analyzing the uploaded research paper PDF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 2\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 26\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quota exceeded, retrying in 30 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 2\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 53\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quota exceeded, retrying in 60 seconds...\n",
            "\n",
            "## Analysis Results\n",
            "### Summary\n",
            "## Comprehensive Analysis of Research on Cyber Attack Detection in UAVs\n",
            "\n",
            "This analysis synthesizes the provided information on research gaps, challenges, future work, and limitations in cyber attack detection for UAVs.\n",
            "\n",
            "**1. Synthesizing Key Points:**\n",
            "\n",
            "* **Gaps:** Existing methods, both residue-based and learning-based, have limitations. Residue-based methods struggle with high-dimensional, non-Gaussian data. Learning-based methods are susceptible to noise, require large datasets, and often lack contextual awareness. There's a need for integrated approaches, broader attack detection capabilities (beyond FDI), and advanced residue analysis techniques.\n",
            "* **Challenges:** Developing robust and effective detection systems, particularly for FDI attacks, is challenging.  Overcoming the limitations of individual methods (residue-based and learning-based) and creating effective hybrid approaches is crucial.  Expanding detection capabilities to other attack types and reducing data dependency for learning-based methods are also significant challenges.\n",
            "* **Future Work:**  Research should focus on extending detection capabilities to a broader range of attacks (DoS, replay), improving residue analysis techniques (beyond EKF), enhancing learning-based methods (exploring architectures like GNNs and incorporating attention mechanisms), and developing more sophisticated methods for combining residue-based and learning-based approaches.\n",
            "* **Limitations:** Residue-based methods are limited by their assumptions about data dimensionality and distribution. Learning-based methods are susceptible to noise, require large datasets, and can lack contextual awareness due to architectural constraints. Using either method in isolation is insufficient.\n",
            "\n",
            "\n",
            "**2. Identifying Common Themes/Patterns:**\n",
            "\n",
            "A recurring theme is the need for **hybrid approaches** that combine the strengths of residue-based and learning-based methods.  Another key theme is the need for **robustness**, both to noisy sensor data and to a wider range of attack types.  The limitations of existing individual approaches consistently point towards the need for more sophisticated and integrated solutions.  **Contextual awareness** in learning-based methods emerges as a critical requirement for effective detection.\n",
            "\n",
            "**3. Analyzing Relationships Between Different Aspects:**\n",
            "\n",
            "The limitations of individual methods directly drive the need for hybrid approaches.  The challenges in developing these hybrid approaches stem from the need to overcome the specific limitations of each constituent method.  Future work is directed towards addressing these limitations and challenges, focusing on developing more robust, context-aware, and broadly applicable detection systems.  The focus on FDI attacks in current research provides a starting point for extending to other attack types, highlighting the iterative nature of research progress.\n",
            "\n",
            "**4. Broader Implications for the Field:**\n",
            "\n",
            "The research on cyber attack detection in UAVs has significant implications for the broader field of cybersecurity.  As UAVs become increasingly prevalent in various applications (critical infrastructure monitoring, delivery services, surveillance), ensuring their security is paramount.  Developing robust and effective detection systems is crucial for preventing malicious actors from compromising UAV operations and causing physical damage, data breaches, or disruption of services.  Advances in this area can contribute to the development of more secure and reliable autonomous systems in general.\n",
            "\n",
            "**5. Structured Summary of the Overall State of Research:**\n",
            "\n",
            "**Topic:** Cyber Attack Detection in UAVs\n",
            "\n",
            "* **Overall Research Gaps:**  Lack of robust and context-aware methods capable of detecting a wide range of cyber-attacks in UAVs under realistic conditions (noisy data, limited training data).  Current methods are often limited to specific attack types (e.g., FDI) and struggle with the complexities of real-world UAV data.\n",
            "* **Key Challenges:** Developing hybrid approaches that effectively combine the strengths of residue-based and learning-based methods while mitigating their individual weaknesses.  Improving robustness to noise, handling high-dimensional and non-Gaussian data, and expanding detection capabilities to encompass diverse attack strategies.  Reducing data dependency for learning-based methods is also a significant challenge.\n",
            "* **Future Research Directions:**  Exploring advanced residue analysis techniques (beyond EKF), developing more sophisticated learning-based models (GNNs, attention mechanisms), creating robust hybrid frameworks, and extending detection capabilities to cover a broader spectrum of attacks (DoS, replay).  Investigating methods for reducing data dependency in learning-based approaches (transfer learning, few-shot learning).\n",
            "* **Major Limitations:**  Residue-based methods are limited by assumptions of low dimensionality and Gaussian data.  Learning-based methods are susceptible to noise, require large datasets, and can lack contextual awareness.  Using either method in isolation is generally insufficient for robust and comprehensive attack detection.\n",
            "* **Interconnections Between Different Aspects:** The limitations of individual methods directly motivate the need for hybrid approaches.  The challenges in developing effective hybrid methods arise from the need to address the specific weaknesses of each constituent method.  Future research is focused on overcoming these limitations and challenges to create more robust, context-aware, and broadly applicable detection systems. The current focus on FDI attacks provides a foundation for expanding to other attack types, demonstrating the iterative and interconnected nature of research progress in this field.\n",
            "\n",
            "\n",
            "This structured summary provides a cohesive overview of the state of research on cyber attack detection in UAVs, highlighting the key gaps, challenges, future directions, limitations, and the interconnections between these aspects.  It emphasizes the need for continued research to develop more sophisticated and effective methods for securing UAVs against increasingly sophisticated cyber threats.\n",
            "\n",
            "### Agent Analyses\n",
            "#### Research Gaps\n",
            "## Chain-of-Thought Analysis of Research Gaps\n",
            "\n",
            "**1. Extracting relevant information related to research gaps:**\n",
            "\n",
            "* \"methods leverage machine learning to identify anomalies, but they encounter issues such as susceptibility to noisy sensor data and reliance on large datasets.\"\n",
            "* \"many existing learning-based approaches emphasize either localized point representations or recursive state transitions, which restrict their capacity for parallel processing and limit contextual awareness.\"\n",
            "* \"these limitations underscore the necessity of developing a method that integrates the advantages of both approaches while overcoming their inherent shortcomings.\"\n",
            "* \"residue-based techniques [...] face significant drawbacks: their assumption of low dimensional or Gaussian data diminishes their effectiveness\"\n",
            "* \"Future work will involve extending the framework to handle a broader range of cyber-attacks and investigating advanced residue [...]\"\n",
            "\n",
            "**2. Summarizing the research gaps:**\n",
            "\n",
            "The text identifies several key gaps in current research on cyber-attack detection in UAVs:\n",
            "\n",
            "* **Limitations of Machine Learning:** Current machine learning methods are susceptible to noisy sensor data, require large datasets, and often focus on localized representations or recursive transitions, hindering parallel processing and contextual awareness.\n",
            "* **Limitations of Residue-based Methods:**  Traditional residue-based methods struggle with high-dimensional and non-Gaussian data, limiting their effectiveness in real-world scenarios.\n",
            "* **Lack of Integrated Approaches:**  There's a need for methods that combine the strengths of both residue-based and learning-based approaches while mitigating their respective weaknesses.\n",
            "* **Limited Scope of Attack Detection:** Current research primarily focuses on specific attack types (like FDI), leaving a gap in detection capabilities for a broader range of cyber-attacks.\n",
            "* **Unexplored Residue Analysis:** Advanced residue analysis techniques remain under-investigated, presenting an opportunity for improvement in attack detection.\n",
            "\n",
            "**3. Suggesting actionable insights and research directions:**\n",
            "\n",
            "* **Robust Machine Learning:** Develop machine learning models that are robust to noisy sensor data and require less extensive training data. Explore alternative data representation techniques that capture contextual information and enable parallel processing (e.g., graph-based methods).\n",
            "* **Advanced Residue Analysis:** Investigate novel residue analysis techniques that can handle high-dimensional and non-Gaussian data. This could involve developing new statistical methods or adapting existing ones.\n",
            "* **Hybrid Approaches:** Design hybrid frameworks that integrate residue-based and learning-based methods. This could involve using residue analysis to pre-process data for machine learning models or combining the outputs of both approaches for more accurate detection.\n",
            "* **Broader Attack Detection:** Extend existing methods to detect a wider range of cyber-attacks beyond FDI, including DoS and replay attacks. This requires understanding the unique characteristics of different attack types and developing tailored detection strategies.\n",
            "* **Adaptive Detection Systems:** Develop adaptive detection systems that can adjust to changing attack strategies and environmental conditions. This could involve using reinforcement learning or other adaptive techniques.\n",
            "\n",
            "**4. Providing specific examples and evidence:**\n",
            "\n",
            "* **Evidence for noise susceptibility:** \"methods leverage machine learning to identify anomalies, but they encounter issues such as susceptibility to noisy sensor data...\"\n",
            "* **Evidence for limitations of residue-based methods:**  \"their assumption of low dimensional or Gaussian data diminishes their effectiveness in [...]\"\n",
            "* **Evidence for the need for integrated approaches:** \"these limitations underscore the necessity of developing a method that integrates the advantages of both approaches...\"\n",
            "* **Evidence for limited attack scope:**  \"Future work will involve extending the framework to handle a broader range of cyber-attacks...\"\n",
            "* **Performance comparison in Tables I and II:** The tables showcasing the performance of different methods (CUSUM, SPRT, BHT, SVM, CNN, LSTM, and the proposed Quadformer) under different noise models and attack types provide concrete evidence of the varying effectiveness of existing techniques, further highlighting the need for improvement.  The proposed Quadformer shows improved performance, but further research is clearly needed to address the identified gaps.\n",
            "\n",
            "\n",
            "**5. Drawing connections between different aspects of the research:**\n",
            "\n",
            "The identified research gaps are interconnected. For example, the limitations of existing machine learning methods (noise susceptibility, data requirements) can be partially addressed by incorporating robust residue analysis techniques. Similarly, developing hybrid approaches requires a deep understanding of both residue-based and learning-based methods and their respective strengths and weaknesses. Addressing the limited scope of current attack detection requires investigating new residue analysis methods and adapting machine learning models to recognize different attack patterns.  By addressing these interconnected gaps, researchers can develop more effective and comprehensive cyber-attack detection systems for UAVs.\n",
            "\n",
            "#### Challenges\n",
            "## Chain-of-Thought Analysis of Challenges in Cyber Attack Detection for UAVs\n",
            "\n",
            "Here's a structured analysis of the challenges based on the provided text:\n",
            "\n",
            "**1. Extracting Relevant Information Related to Challenges:**\n",
            "\n",
            "* **Limitations of existing methods:** The text highlights the limitations of both residue-based and learning-based methods for attack detection. Residue-based methods struggle with non-Gaussian and high-dimensional data, while learning-based methods are susceptible to noisy sensor data, require large datasets, and can have limited contextual awareness due to a focus on localized representations or recursive state transitions.\n",
            "* **Focus on FDI attacks:** The text specifically identifies False Data Injection (FDI) attacks as a key challenge due to their prevalence, ease of execution, and covert nature.\n",
            "* **Need for a combined approach:** The text emphasizes the need for a new method that combines the strengths of residue-based and learning-based approaches while overcoming their individual weaknesses.\n",
            "* **Extending the framework:**  Future work will involve extending the proposed framework to handle a broader range of cyber-attacks and investigating advanced residue analysis.  This implies a current limitation in the scope of attack types handled.\n",
            "\n",
            "**2. Analyzing the Extracted Information:**\n",
            "\n",
            "The core challenge is developing a robust and effective cyber-attack detection system for UAVs, specifically focusing on FDI attacks. Existing methods, categorized as residue-based and learning-based, each present significant shortcomings. Residue-based methods are ill-equipped to handle the complexities of real-world UAV data, which is often high-dimensional and non-Gaussian. Learning-based methods, while promising, suffer from practical limitations like noise sensitivity, data dependency, and limited contextual awareness due to architectural constraints. The text argues for a hybrid approach that leverages the strengths of both methodologies while mitigating their weaknesses.  Furthermore, the current framework appears limited in the types of attacks it can handle, posing a challenge for future development.\n",
            "\n",
            "\n",
            "**3. Suggesting Actionable Insights and Research Directions:**\n",
            "\n",
            "* **Develop hybrid approaches:** Explore combining residue-based methods with learning-based techniques. For example, use machine learning to learn the distribution of residues under normal operation and detect deviations that indicate attacks.\n",
            "* **Robustness to noise:** Investigate techniques to make learning-based methods more robust to noisy sensor data. This could involve using robust loss functions, data augmentation techniques, or incorporating noise models into the training process.\n",
            "* **Contextual awareness:** Develop learning-based models that can capture longer-range dependencies and contextual information.  This might involve attention mechanisms (as hinted at with \"Quadformer\" in the text), graph neural networks, or other architectures capable of integrating temporal and spatial information.\n",
            "* **Addressing broader attack types:** Research should focus on expanding the framework's capabilities to detect and mitigate a wider variety of attack strategies beyond FDI, including DoS and replay attacks. This might involve incorporating different data sources or developing more sophisticated anomaly detection algorithms.\n",
            "* **Reduce data dependency:** Explore methods to reduce the reliance on large datasets for training learning-based models. This could involve transfer learning, few-shot learning, or synthetic data generation.\n",
            "\n",
            "**4. Providing Specific Examples and Evidence:**\n",
            "\n",
            "* **\"Residue-based techniques...face significant drawbacks: their assumption of low dimensional or gaussian data diminishes their effectiveness...\"** This directly states the limitation of residue-based methods.\n",
            "* **\"...learning-based approaches emphasize either localized point representations or recursive state transitions, which restrict their capacity for parallel processing and limit contextual awareness.\"** This points to the architectural limitations of current learning-based methods.\n",
            "* **\"Our research focuses on addressing these FDI attacks.\"**  This highlights the specific attack type being targeted.\n",
            "* **\"Future work will involve extending the framework to handle a broader range of cyber attacks...\"**  This explicitly states the need to address a wider range of attacks.\n",
            "* **\"0.92 0.97 0.94...ours quadformer\"**  This suggests the use of a transformer-based model, potentially for improved contextual awareness.\n",
            "\n",
            "**5. Drawing Connections Between Different Aspects of the Research:**\n",
            "\n",
            "The challenges identified in the text are interconnected. The limitations of individual methods (residue-based and learning-based) necessitate the development of hybrid approaches. The focus on FDI attacks shapes the specific requirements for the detection system.  The need for robustness to noise and improved contextual awareness drives the exploration of new architectures and training techniques. The desire to handle a broader range of attacks and reduce data dependence further motivates research into more advanced and adaptable methods.  The mentioned \"Quadformer\" and its improved performance metrics suggest a potential pathway to address some of these challenges, particularly regarding contextual awareness.\n",
            "\n",
            "#### Future Work\n",
            "## Chain-of-Thought Analysis of Future Work\n",
            "\n",
            "**1. Extracting relevant information related to future work:**\n",
            "\n",
            "The context mentions future work in two distinct areas:\n",
            "\n",
            "* **Extending the framework to handle a broader range of cyber attacks:** This is explicitly stated as a future direction. While the current research focuses on False Data Injection (FDI) attacks, future work aims to encompass other attack types like Denial-of-Service (DoS) and replay attacks.\n",
            "* **Investigating advanced residue and learning-based approaches:** The text highlights the combination of residue-based and learning-based methods in the proposed framework. Future work could involve refining these individual approaches or exploring new combinations to improve detection performance.  The context mentions the use of an Extended Kalman Filter (EKF) and a Transformer-based architecture, suggesting potential areas for improvement within these specific methods.\n",
            "\n",
            "\n",
            "**2.  Summarizing the future work:**\n",
            "\n",
            "The future research trajectory focuses on two key enhancements: broadening the scope of detectable attacks and improving the underlying detection mechanisms.  This involves moving beyond FDI attacks to consider other prevalent attack vectors and refining the synergy between residue analysis and learning-based detection.\n",
            "\n",
            "**3. Suggesting actionable insights and research directions:**\n",
            "\n",
            "* **Expanding attack coverage:**  Investigate the characteristics of DoS and replay attacks in the context of UAVs.  This includes understanding their impact on sensor readings, communication channels, and control systems.  Develop specific residue-based features or learning-based models tailored to these attack types.  For example, for DoS attacks, analyzing communication patterns and signal strength could be crucial. For replay attacks, detecting time discrepancies and inconsistencies in sensor data could be explored.\n",
            "* **Enhancing residue analysis:** Explore alternative residue generation methods beyond the EKF.  Consider using higher-order filters or nonlinear observers to capture more complex dynamics and improve the sensitivity to subtle anomalies.  Investigate advanced statistical methods for residue analysis, moving beyond simple thresholding.\n",
            "* **Improving learning-based detection:**  Experiment with different neural network architectures beyond Transformers.  Explore the use of Graph Neural Networks (GNNs) to model the interconnected nature of UAV components and dependencies.  Investigate transfer learning techniques to leverage pre-trained models and reduce the need for large training datasets.  Consider incorporating attention mechanisms to focus on the most relevant features for attack detection.\n",
            "* **Combining residue and learning:** Develop more sophisticated methods for fusing the outputs of residue-based and learning-based approaches.  Explore ensemble methods or hierarchical architectures that combine the strengths of both techniques.  Investigate the use of reinforcement learning to optimize the combination strategy dynamically.\n",
            "\n",
            "**4. Providing specific examples and evidence from the context:**\n",
            "\n",
            "* \"attacks targeting uavs are typically classified into categories such as denialofservice (dos) attacks, false data injection (fdi) attacks, and replay attacks.\" This explicitly identifies the attack types to be considered in future work.\n",
            "* \"first, the ekfs model prediction relies on firstorder linearization, leaving higherorder terms in the residue.\" This suggests a specific limitation of the current EKF-based approach and points towards exploring higher-order methods.\n",
            "* \"this, in turn, enhances the effectiveness of neural networkbased detection methods.\" This highlights the importance of the connection between residue analysis and learning-based methods, suggesting further investigation into their synergy.\n",
            "* \"building upon transformer frameworks designed for kalman filter...\" This mentions the use of Transformers and suggests exploring other architectures.\n",
            "\n",
            "\n",
            "**5. Drawing connections between different aspects of the research:**\n",
            "\n",
            "The focus on FDI attacks in the current work provides a foundation for extending to other attack types. The understanding of FDI attack characteristics can inform the development of detection methods for DoS and replay attacks.  The limitations of the EKF, as mentioned in the context, directly motivate the exploration of alternative residue generation methods.  The success of the Transformer-based approach encourages further investigation into advanced learning-based techniques and their integration with residue analysis.  By connecting these different aspects, a comprehensive and impactful research agenda for future work can be established.\n",
            "\n",
            "#### Limitations\n",
            "## Chain-of-Thought Analysis of Limitations\n",
            "\n",
            "Here's a structured analysis of the limitations presented in the provided text:\n",
            "\n",
            "**1. Extracting Relevant Information Related to Limitations:**\n",
            "\n",
            "* **Residue-based methods:** \"these methods face significant drawbacks: their assumption of low dimensional or gaussian data diminishes their effectiveness\"\n",
            "* **Learning-based methods (specifically focusing on existing ones, not the proposed method):** \"they encounter issues such as susceptibility to noisy sensor data and reliance on large datasets. moreover, many existing learningbased approaches emphasize either localized point representations or recursive state transitions, which restrict their capacity for parallel processing and limit contextual awareness.\"\n",
            "* **Individual use of either method:**  \"these limitations underscore the necessity of developing a method that integrates the advantages of both approaches while overcoming their inherent shortcomings.\"  This implies that using either residue-based or learning-based methods *alone* is insufficient.\n",
            "\n",
            "\n",
            "**2. Analyzing the Extracted Sections:**\n",
            "\n",
            "* **Residue-based methods:**  The core limitation is the assumption of low-dimensional or Gaussian data.  Real-world sensor data, especially in UAV systems, can be highly complex and non-Gaussian due to various factors like environmental noise and system dynamics.  This mismatch between assumptions and reality reduces the effectiveness of these methods.\n",
            "* **Learning-based methods:**  Three key limitations are identified:\n",
            "    * **Susceptibility to noisy data:**  Learning-based models, while powerful, can be negatively impacted by noisy sensor readings, leading to inaccurate predictions or classifications.\n",
            "    * **Reliance on large datasets:** Training effective learning-based models often requires substantial amounts of labeled data, which can be expensive and time-consuming to acquire, especially for specific attack scenarios.\n",
            "    * **Limited parallel processing and contextual awareness:**  Existing approaches focusing on localized point representations or recursive state transitions hinder parallel processing and limit the model's ability to understand the broader context of the sensor data.\n",
            "\n",
            "\n",
            "**3. Suggesting Actionable Insights and Research Directions:**\n",
            "\n",
            "* **Robust residue-based methods:** Explore modifications to existing residue-based methods to handle non-Gaussian and high-dimensional data. This could involve using non-parametric statistical tests or developing new residue generation techniques.\n",
            "* **Noise-resistant learning:** Investigate techniques to improve the robustness of learning-based methods to noisy sensor data.  This might include data pre-processing, robust loss functions, or adversarial training.\n",
            "* **Efficient data utilization:**  Develop methods that can effectively learn from smaller datasets or leverage techniques like transfer learning to reduce the data burden.\n",
            "* **Context-aware and parallel processing:** Explore architectures that incorporate contextual information and enable parallel processing, such as attention mechanisms or graph neural networks.  The paper's proposed \"Quadformer\" likely addresses these points, suggesting a research direction of analyzing and improving transformer-based models for this application.\n",
            "* **Hybrid approaches:**  As the paper suggests, combining residue-based and learning-based methods could offer a promising direction.  This might involve using residue-based methods for initial anomaly detection and then employing learning-based methods for more fine-grained classification or analysis.\n",
            "\n",
            "\n",
            "**4. Providing Specific Examples and Evidence:**\n",
            "\n",
            "* **Table I and II:**  While the tables show the proposed method outperforming traditional methods, they don't directly illustrate the limitations. However, they provide a benchmark against which improvements addressing these limitations can be measured.  Future work could include experiments with specifically crafted noisy datasets or limited training data to demonstrate the impact of these limitations and the effectiveness of proposed solutions.\n",
            "* **Focus on FDI attacks:**  The justification for focusing on FDI attacks (\"higher prevalence and ease of execution compared to replay attacks, as well as their more covert and deceptive nature relative to dos attacks\") highlights the practical relevance of addressing the limitations related to detecting these specific attacks.\n",
            "\n",
            "\n",
            "**5. Drawing Connections Between Different Aspects of the Research:**\n",
            "\n",
            "The limitations of individual methods (residue-based and learning-based) directly motivate the need for a combined approach. The identified shortcomings, such as susceptibility to noise and limited contextual awareness, provide specific targets for improvement. The focus on FDI attacks provides a concrete application area where overcoming these limitations is crucial for ensuring the security and reliability of UAV systems.  The proposed \"Quadformer\" is positioned as a solution addressing these limitations, emphasizing the connection between the identified weaknesses and the proposed innovation.\n",
            "\n",
            "### NLP Details\n",
            "**POS Tags**: [('2501.07597v1', 'NUM', 'nummod'), ('cs.ro', 'NOUN', 'nsubj'), ('10', 'NUM', 'nummod'), ('jan', 'PROPN', 'npadvmod'), ('2025', 'NUM', 'nummod'), ('arxiv', 'PROPN', 'nsubj'), ('learningbased', 'VERB', 'ROOT'), ('detection', 'NOUN', 'dobj'), ('of', 'ADP', 'prep'), ('gps', 'PROPN', 'pobj')]...\n",
            "**Named Entities**: [('10 jan 2025', 'DATE', ''), ('wang', 'PERSON', ''), ('zhaohua yang!', 'PERSON', ''), ('jialu li', 'PERSON', ''), ('ling shi!', 'PERSON', ''), ('uav', 'ORG', ''), ('nongaussian', 'NORP', ''), ('i.', 'PERSON', ''), ('1', 'CARDINAL', ''), ('2', 'CARDINAL', '')]...\n",
            "\n",
            "Results saved to analysis_4071e272.json\n",
            "\n",
            "\n",
            "Select input type: 1. Text, 2. PDF\n",
            "Enter your query: \n",
            "\n",
            "Searching for relevant papers...\n",
            "Found 10 papers. Analyzing...\n",
            "\n",
            "## Analysis Results\n",
            "### Summary\n",
            "## Comprehensive Analysis of the State of LLM Research\n",
            "\n",
            "This analysis synthesizes the provided information on research gaps, challenges, future work, and limitations of Large Language Models (LLMs).\n",
            "\n",
            "**1. Synthesizing Key Points from Each Category:**\n",
            "\n",
            "* **Research Gaps:** Foundational gaps exist in LLM-integrated applications (terminology, methods), explainability and reliability of LLM judges, intersection of LLMs and graph analytics, and understanding Code LLMs and their base models.\n",
            "* **Challenges:**  LLMs face challenges in generalization and reasoning (especially with graphs and human simulation), technical limitations (synchronous function calling, bias in judgment), application integration (immature tools, information loss via simplified APIs), and evaluation/explainability.\n",
            "* **Future Work:**  Future research should focus on improving LLM-integrated applications, advancing LLM capabilities for graph analytics, enhancing Code LLMs, addressing reliability and bias in LLM judges, and exploring novel applications.\n",
            "* **Limitations:** LLMs are limited by realism and generalization issues in human simulation, technical constraints of synchronous function calling, bias and reliability problems in LLM judges, and lack of application-level awareness in current LLM services.\n",
            "\n",
            "**2. Identifying Common Themes and Patterns:**\n",
            "\n",
            "A recurring theme is the tension between the impressive capabilities of LLMs and the need for further development to address fundamental issues.  Several categories highlight the need for improved *explainability* and *reliability*.  Another common pattern is the challenge of integrating LLMs into real-world applications and systems, whether it's due to technical limitations, lack of standardized practices, or the need for better application-level awareness.\n",
            "\n",
            "**3. Analyzing Relationships Between Different Aspects:**\n",
            "\n",
            "* **Gaps drive future work:**  The identified research gaps directly inform the suggested future research directions. For instance, the lack of standardized methods for LLM-integrated applications necessitates the development of such methods as future work.\n",
            "* **Challenges hinder progress:** The current limitations and challenges obstruct the full realization of LLM potential.  Bias in LLM judges, for example, limits their use in evaluating other LLMs and alignment approaches.\n",
            "* **Future work aims to overcome limitations:**  Proposed future work directly addresses the identified limitations.  For example, research on asynchronous function calling aims to overcome the limitations of synchronous calls.\n",
            "\n",
            "\n",
            "**4. Broader Implications for the Field:**\n",
            "\n",
            "The identified gaps, challenges, and limitations underscore that while LLMs hold immense promise, they are not a panacea.  Addressing these issues is crucial for responsible and beneficial deployment of LLMs across various domains.  The development of standardized practices, robust evaluation metrics, and explainable AI techniques will be essential for building trust and ensuring the ethical use of LLMs.  Furthermore, interdisciplinary research combining LLMs with other fields like graph analytics and cognitive science will unlock new possibilities and drive innovation.\n",
            "\n",
            "**5. Structured Summary of the State of LLM Research:**\n",
            "\n",
            "* **Overall Research Gaps:**  Foundational gaps exist in integrating LLMs into applications, understanding and mitigating bias in LLM judgment, exploring the intersection of LLMs and structured data like graphs, and optimizing Code LLMs.\n",
            "* **Key Challenges:**  LLMs struggle with generalization, particularly in complex reasoning tasks and human simulation.  Technical limitations like synchronous function calling and bias in judgment hinder progress.  Integrating LLMs into applications is challenging due to immaturity of the field and lack of application-level awareness in current LLM services.\n",
            "* **Future Research Directions:**  Future research should focus on developing standardized frameworks and tools for LLM-integrated applications, improving graph reasoning and human simulation capabilities, mitigating bias and enhancing explainability, optimizing asynchronous LLM operations, and exploring novel applications like LLM-OSR.\n",
            "* **Major Limitations:**  Current LLMs are limited by a lack of realism in human simulation, technical constraints in efficient external interaction, bias and inconsistency in judgment, and a lack of application-level awareness that hinders optimization in complex workflows.\n",
            "* **Interconnections:** Research gaps directly motivate future research directions.  Current challenges limit the potential of LLMs and must be addressed. Future work aims to overcome these limitations and unlock the full capabilities of LLMs.  Progress in one area, such as explainability, can positively impact other areas, like application integration and evaluation.\n",
            "\n",
            "\n",
            "This analysis demonstrates that LLM research is a rapidly evolving field with significant potential but also substantial challenges. Addressing these challenges through focused research and development will be crucial for realizing the transformative impact of LLMs across diverse domains.\n",
            "\n",
            "### Agent Analyses\n",
            "#### Research Gaps\n",
            "## Chain-of-Thought Analysis of Research Gaps in LLMs based on the provided text\n",
            "\n",
            "**1. Extracting relevant sections related to research gaps:**\n",
            "\n",
            "* **Lack of established terminology, concepts, and methods for LLM-integrated application engineering:** \"While LLM-integrated application engineering is emerging as a new discipline, its terminology, concepts, and methods need to be established.\"\n",
            "* **Limited understanding of LLM judge reliability and explainability:** \"However, concerns regarding its reliability have emerged, due to LLM judges' biases and inconsistent decision-making... the employed evaluation metrics often lack adequate explainability.\"\n",
            "* **Open problems and future directions in LLMs and graph analytics:** \"We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.\"  (While not explicitly stated, this implies existing gaps.)\n",
            "* **Need for better understanding of the impact of base models and Code LLMs:** \"Our research not only assists developers of Code LLMs in choosing base models for the development of more advanced LLMs but also provides insights for practitioners to better understand key improvement directions for Code LLMs.\"\n",
            "\n",
            "\n",
            "**2. Analyzing these sections to provide a clear and concise summary:**\n",
            "\n",
            "The provided text highlights several research gaps related to LLMs:\n",
            "\n",
            "* **Foundational Gaps in LLM-integrated Applications:**  A lack of standardized terminology, concepts, and methods hinders the development and analysis of LLM-integrated applications. This represents a fundamental gap that needs addressing for the field to mature.\n",
            "* **Explainability and Reliability of LLM Judges:**  LLMs are being used as judges for evaluating other LLMs, but their reliability and the explainability of their judgments are questionable.  This raises concerns about the validity of using LLMs in such evaluative roles.\n",
            "* **Intersection of LLMs and Graph Analytics:**  While the text mentions exploration of open problems and future directions in this area, the specifics are not detailed. This suggests a broad area ripe for further investigation.\n",
            "* **Understanding Code LLMs and Base Models:**  More research is needed to understand the impact of different base models on the performance of Code LLMs and to identify key areas for improvement.\n",
            "\n",
            "\n",
            "**3. Suggesting actionable insights or research directions based on identified gaps:**\n",
            "\n",
            "* **Develop standardized frameworks and best practices for LLM-integrated application engineering:** This could involve creating common vocabularies, design patterns, and evaluation metrics.\n",
            "* **Investigate methods for improving the explainability and reliability of LLM judges:** Research could focus on developing techniques for understanding LLM decision-making processes and mitigating biases.\n",
            "* **Explore specific research questions within the intersection of LLMs and graph analytics:** Examples include: How can LLMs be effectively used for graph generation, analysis, and querying? What are the limitations of current approaches? How can graph structures be best represented for LLM consumption?\n",
            "* **Conduct comparative studies of different base models and their impact on Code LLM performance:** This research could inform the development of more effective Code LLMs tailored for specific software engineering tasks.\n",
            "\n",
            "\n",
            "**4. Providing specific examples and evidence from the context:**\n",
            "\n",
            "* **Example of application integration gap:** \"LLM-integrated applications, on the other hand, are software systems that leverage an LLM...While LLM-integrated application engineering is emerging as new discipline, its terminology, concepts and methods need to be established.\"\n",
            "* **Example of LLM judge reliability gap:** \"LLM-as-a-Judge has been widely applied...However, concerns regarding its reliability have emerged, due to LLM judges' biases and inconsistent decision-making.\"\n",
            "* **Example of graph analytics and LLMs gap (implicit):**  \"...We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.\"\n",
            "* **Example of Code LLM and base model gap:** \"...We investigate the performance differences between general LLMs and Code LLMs...to better understand key improvement directions for Code LLMs.\"\n",
            "\n",
            "\n",
            "**5. Drawing connections between different aspects of the research:**\n",
            "\n",
            "The identified research gaps are interconnected. For instance, advancements in understanding LLM decision-making (relevant to the LLM judge reliability gap) could contribute to developing more robust and explainable LLM components within integrated applications. Similarly, a better understanding of base models and their impact on Code LLMs can inform the design of more effective LLM-integrated development tools. Addressing the foundational gaps in LLM-integrated application engineering will facilitate research in other areas by providing a common framework and vocabulary.  Furthermore, progress in graph analytics with LLMs could unlock new applications and capabilities for LLM-integrated systems, creating a synergistic relationship between these research areas.\n",
            "\n",
            "#### Challenges\n",
            "## Chain-of-Thought Analysis of LLM Challenges\n",
            "\n",
            "**1. Extracting Relevant Information Related to Challenges:**\n",
            "\n",
            "* **Generalization of graph tasks:** LLMs offer advantages but still face challenges in generalizing graph tasks.  The text mentions \"existing remaining challenges and future directions\" in LLM-based generative graph analytics (LLM-GGA), specifically in graph query processing (LLM-GQP), graph inference and learning (LLM-GIL), and graph-LLM-based applications.\n",
            "* **LLM-based human simulation:** \"Significant gaps between LLM-based human simulations and real-world observations\" present a dual challenge in accurately simulating human behavior.  Design issues, data collection, LLM generation, and evaluation are mentioned as areas needing improvement.\n",
            "* **Synchronous function calling:** Current LLM function calling is synchronous, limiting LLM operation and concurrent function execution. This is presented as a limitation addressed by the proposed AsyncLM system.\n",
            "* **Evaluation of LLM alignment approaches:**  The reliability of LLM-as-a-Judge is questioned due to biases and inconsistent decision-making. Existing evaluation metrics lack explainability, hindering a thorough understanding of LLM judgment.\n",
            "* **Building LLM-integrated applications:** While promising, integrating LLMs into applications presents challenges. The text highlights the nascent nature of the field and the need for further research and theory building.\n",
            "* **Application-level information loss:** LLM-based applications built on public LLM services lose essential application-level information due to oversimplified request-level APIs. This hinders optimization and understanding of complex workflows.\n",
            "\n",
            "\n",
            "**2. Analyzing and Summarizing the Challenges:**\n",
            "\n",
            "The challenges revolve around several key areas:\n",
            "\n",
            "* **Generalization and Reasoning:** LLMs struggle to generalize knowledge to complex structured data like graphs and to accurately simulate human reasoning in various scenarios.\n",
            "* **Technical Limitations:** Synchronous function calling restricts the efficiency and capabilities of LLMs.  Bias and inconsistency in LLM judgment create difficulties in evaluating and aligning LLMs with human preferences.\n",
            "* **Application Integration:**  Building LLM-integrated applications is challenging due to the immaturity of the field and the lack of robust tools and methodologies. Simplified APIs offered by public LLM services lead to information loss and suboptimal performance.\n",
            "* **Evaluation and Explainability:** Evaluating the performance and reliability of LLMs, especially in complex tasks like human simulation and judgment, is difficult.  Lack of explainability in evaluation metrics further complicates understanding LLM behavior.\n",
            "\n",
            "\n",
            "**3. Actionable Insights and Research Directions:**\n",
            "\n",
            "* **Graph Reasoning:** Develop new techniques for representing graph data and integrating them into LLM architectures to improve generalization and reasoning on graph-based tasks. Explore graph-specific prompting strategies and fine-tuning methods.\n",
            "* **Asynchronous LLM Operations:**  Further develop and optimize asynchronous function calling mechanisms to enhance LLM efficiency and enable more complex, concurrent operations.\n",
            "* **Debiasing and Explainability:** Investigate methods for mitigating bias and improving the consistency of LLM judgment. Develop more explainable evaluation metrics to gain deeper insights into LLM decision-making processes.\n",
            "* **LLM-Integrated Application Development:**  Develop standardized frameworks and tools for building LLM-integrated applications.  Design richer APIs for public LLM services that preserve application-level information.\n",
            "* **Human Simulation and Evaluation:** Improve data collection methods and LLM generation techniques for more realistic human simulations. Develop robust evaluation metrics specifically tailored to assessing the quality and fidelity of LLM-based human simulations.\n",
            "\n",
            "\n",
            "**4. Specific Examples and Evidence:**\n",
            "\n",
            "* **Graph Reasoning:** \"LLM-GGA with three categories: LLM-GQP, LLM-GIL, and graph-LLM-based applications\" highlights the specific areas within graph analytics posing challenges.\n",
            "* **Human Simulation:** \"Significant gaps between LLM-based human simulations and real-world observations\" directly states the challenge and the provided GitHub link offers resources for further research.\n",
            "* **Synchronous Function Calling:**  \"AsyncLM, a system for asynchronous LLM function calling\" is presented as a solution to the specific limitation of synchronous calls.\n",
            "* **Evaluation of LLM Alignment:**  \"Concerns regarding its reliability have emerged, due to LLM judges' biases and inconsistent decision-making\" points to the specific challenges in LLM evaluation.\n",
            "* **Application Integration:** \"Though challenges persist, integrating LLMs may revolutionize the way software systems are built\" acknowledges the difficulties while emphasizing the potential.\n",
            "\n",
            "\n",
            "**5. Drawing Connections Between Different Aspects:**\n",
            "\n",
            "The challenges are interconnected. For instance, improved graph reasoning capabilities could enhance the realism of LLM-based human simulations in social network contexts.  Similarly, more explainable evaluation metrics could contribute to better understanding and mitigating biases in LLM judgment, leading to more reliable LLM-integrated applications.  Addressing the technical limitations of synchronous function calling can unlock new possibilities for complex applications and more sophisticated human simulations.  Overall, progress in one area can facilitate advancements in others, driving the field of LLM research and application forward.\n",
            "\n",
            "#### Future Work\n",
            "## Chain-of-Thought Analysis of Future Work for LLMs\n",
            "\n",
            "**1. Extracting relevant sections related to future work:**\n",
            "\n",
            "* \"...This work introduces the LLM Online Spatial-temporal Reconstruction (LLM-OSR) framework...\"  This implies future work could explore and expand upon LLM-OSR applications and capabilities.\n",
            "* \"...We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.\" This directly points towards future research in combining LLMs and graph analytics.\n",
            "* \"...LLM-GQP focuses on an integration of graph analytics techniques and LLM prompts...while LLM-GIL focuses on learning and reasoning over graphs...\" These specific areas (LLM-GQP and LLM-GIL) are highlighted as current research focuses, implying future work will likely build upon these foundations.\n",
            "* \"...LLM-integrated application engineering is emerging as a new discipline, its terminology, concepts and methods need to be established.\" This clearly indicates a need for future work in defining and solidifying the field of LLM-integrated applications.\n",
            "*  \"...This study provides a taxonomy for LLM-integrated applications...It also demonstrates various ways to utilize LLMs in applications, as well as options for implementing such integrations.\" This suggests future work could involve applying and refining this taxonomy, exploring new LLM integrations, and developing best practices for implementation.\n",
            "* \"...Our research not only assists developers of Code LLMs in choosing base models...but also provides insights for practitioners to better understand key improvement directions for Code LLMs.\" This points towards future work in improving Code LLMs based on the insights gained from this research.\n",
            "* \"...LLM-as-a-Judge has been widely applied...However, concerns regarding its reliability have emerged...\" This highlights the need for future work focused on improving the reliability and addressing the biases of LLMs as judges.\n",
            "\n",
            "\n",
            "**2. Analyzing these sections to provide a clear and concise summary:**\n",
            "\n",
            "Future work related to LLMs falls into several key areas:\n",
            "\n",
            "* **Improving LLM-integrated applications:** This includes developing a robust taxonomy, exploring new integration methods, and establishing best practices for application engineering.\n",
            "* **Advancing LLM capabilities for graph analytics:**  This involves further research into LLM-GQP (graph query processing) and LLM-GIL (graph inference and learning), potentially leading to more sophisticated graph-based applications.\n",
            "* **Enhancing Code LLMs:**  Future research should focus on leveraging current findings to improve the performance and selection of base models for Code LLMs.\n",
            "* **Addressing reliability and bias in LLM judges:**  Future efforts should aim to mitigate biases and improve the consistency of LLM-based judgment systems.\n",
            "* **Exploring novel applications like LLM-OSR:**  Further investigation is needed to fully realize the potential of LLM-OSR for spatial-temporal signal reconstruction.\n",
            "\n",
            "**3. Suggesting actionable insights or research directions:**\n",
            "\n",
            "* **Develop standardized evaluation metrics for LLM-integrated applications:** This would allow for better comparison and benchmarking of different approaches.\n",
            "* **Investigate the ethical implications of LLM-based judgment systems:**  This is crucial for ensuring responsible and fair use of these technologies.\n",
            "* **Explore the use of LLMs for automated code generation and debugging:**  This could significantly improve software development efficiency.\n",
            "* **Develop methods for incorporating domain-specific knowledge into LLMs for specialized applications:** This would enhance the performance of LLMs in specific fields.\n",
            "* **Investigate the potential of combining LLMs with other AI techniques, such as reinforcement learning, for more complex tasks.**\n",
            "\n",
            "\n",
            "**4. Providing specific examples and evidence from the context:**\n",
            "\n",
            "*  \"LLM-integrated application engineering is emerging as new discipline...\"  This highlights the need for future work in defining this emerging field.\n",
            "* \"We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.\" This directly calls for further research in this area.\n",
            "* \"LLM-as-a-Judge has been widely applied...However, concerns regarding its reliability have emerged...\"  This provides concrete evidence of the need for future work on LLM reliability.\n",
            "\n",
            "\n",
            "**5. Drawing connections between different aspects of the research:**\n",
            "\n",
            "The development of a robust taxonomy for LLM-integrated applications can inform the development of standardized evaluation metrics. Improvements in Code LLMs can contribute to more efficient software development through automated code generation. Addressing the reliability and bias in LLM judges is crucial for ensuring the ethical use of LLMs in various applications, including graph analytics and software engineering.  The exploration of novel applications like LLM-OSR can open up new possibilities for utilizing LLMs in diverse fields.  Ultimately, these different research directions are interconnected and contribute to the broader goal of advancing LLM capabilities and applications.\n",
            "\n",
            "#### Limitations\n",
            "## Chain-of-Thought Analysis of LLM Limitations\n",
            "\n",
            "**1. Extracting Relevant Information on Limitations:**\n",
            "\n",
            "The following excerpts highlight LLM limitations:\n",
            "\n",
            "* \"studies have revealed significant gaps between LLM-based human simulations and real-world observations, highlighting these dual challenges.\"  This points to a core limitation in accurately simulating human behavior.\n",
            "* \"Large language models (LLMs) use function calls to interface with external tools and data source. However, the current approach to LLM function calling is inherently synchronous, where each call blocks LLM inference, limiting LLM operation and concurrent function execution.\" This reveals a technical limitation in handling external interactions efficiently.\n",
            "* \"LLM-as-a-Judge has been widely applied to evaluate and compare different LLM alignment approaches (e.g., RLHF and DPO). However, concerns regarding its reliability have emerged, due to LLM judges' biases and inconsistent decision-making.\" This exposes a crucial limitation in using LLMs for evaluation due to inherent biases.\n",
            "* \"Public LLM services have to blindly optimize\" suggests a lack of application-level awareness in current LLM services, limiting their effectiveness in complex workflows.\n",
            "\n",
            "\n",
            "**2. Summarizing the Limitations:**\n",
            "\n",
            "The identified limitations fall into several categories:\n",
            "\n",
            "* **Realism and Generalization:** LLM-based human simulations struggle to accurately reflect real-world human behavior, indicating limitations in generalization and understanding of complex social dynamics.\n",
            "* **Technical Constraints:** Synchronous function calling creates bottlenecks in LLM operation, hindering efficient interaction with external tools and data.\n",
            "* **Bias and Reliability:** LLMs used as judges exhibit biases and inconsistencies, raising concerns about their reliability for evaluating other LLMs or alignment approaches.\n",
            "* **Application-Level Awareness:** Current LLM services lack understanding of application-level context, making it difficult to optimize complex workflows involving multiple LLM requests.\n",
            "\n",
            "\n",
            "**3. Actionable Insights and Research Directions:**\n",
            "\n",
            "* **Improving Human Simulation:** Research should focus on incorporating more realistic cognitive models and social dynamics into LLM training to bridge the gap between simulation and real-world behavior.  Investigating new evaluation metrics that go beyond simple task completion and assess the nuances of human-like interaction is crucial.\n",
            "* **Asynchronous Function Calling:** Developing asynchronous function calling mechanisms can significantly improve LLM efficiency and enable more complex, real-time interactions with external systems.\n",
            "* **Mitigating Bias in LLM Judges:**  Research on debiasing techniques and developing more robust evaluation frameworks for LLM judges is essential. Exploring alternative evaluation methods that incorporate human feedback and diverse perspectives could improve reliability.\n",
            "* **Application-Aware LLM Services:** Designing LLM services that are aware of application-level context can enable more effective optimization of complex workflows and improve resource allocation.  This might involve developing new APIs or communication protocols that allow applications to share more information with the LLM service.\n",
            "\n",
            "\n",
            "**4. Specific Examples and Evidence:**\n",
            "\n",
            "* **Realism:** The statement \"significant gaps between LLM-based human simulations and real-world observations\" directly points to the limitation in realism.\n",
            "* **Synchronous Calls:** The description of \"inherently synchronous\" function calls as \"limiting LLM operation and concurrent function execution\" provides clear evidence of the technical constraint.\n",
            "* **Bias:** The mention of \"LLM judges' biases and inconsistent decision-making\" highlights the reliability issues.\n",
            "* **Application Awareness:** The phrase \"Public LLM services have to blindly optimize\" illustrates the lack of application context.\n",
            "\n",
            "\n",
            "**5. Drawing Connections:**\n",
            "\n",
            "The limitations are interconnected. For example, the lack of realism in human simulations can be partly attributed to the technical limitations in processing complex information and interacting with the environment. Similarly, the biases observed in LLM judges might stem from limitations in understanding nuanced contexts and social dynamics. Addressing these interconnected challenges requires a holistic approach that considers both technical advancements and a deeper understanding of human cognition and behavior.  Further research should focus on developing more robust evaluation methods to assess not only task performance but also factors like realism, fairness, and explainability. This will be crucial for building truly reliable and beneficial LLM-based applications.\n",
            "\n",
            "### NLP Details\n",
            "**POS Tags**: [('in', 'ADP', 'prep'), ('the', 'DET', 'det'), ('rapidly', 'ADV', 'advmod'), ('evolving', 'VERB', 'amod'), ('ai', 'ADJ', 'poss'), ('era', 'NOUN', 'pobj'), ('with', 'ADP', 'prep'), ('large', 'ADJ', 'amod'), ('language', 'NOUN', 'compound'), ('models', 'NOUN', 'pobj')]...\n",
            "**Named Entities**: [('llm', 'ORG', ''), ('llm', 'FAC', ''), ('thirteen', 'CARDINAL', ''), ('llm', 'FAC', ''), ('llm', 'GPE', ''), ('one', 'CARDINAL', ''), ('public llm', 'ORG', ''), ('llm', 'GPE', ''), ('llm applications', 'ORG', ''), ('three', 'CARDINAL', '')]...\n",
            "\n",
            "Results saved to analysis_4bf63afc.json\n",
            "\n",
            "\n",
            "Select input type: 1. Text, 2. PDF\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import arxiv\n",
        "import json\n",
        "import asyncio\n",
        "import time\n",
        "import sys\n",
        "from uuid import uuid4\n",
        "from typing import List, Dict, Optional\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "try:\n",
        "    from enhanced_nlp import clean_text, get_pos_tags, extract_named_entities\n",
        "    from prompt_engineering import generate_agent_prompt, generate_summary_prompt\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing enhanced_nlp or prompt_engineering: {e}\")\n",
        "    print(\"Ensure enhanced_nlp.py and prompt_engineering.py are in the same directory.\")\n",
        "    sys.exit(1)\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from google.colab import files\n",
        "import tempfile\n",
        "\n",
        "sys.stdout.flush()\n",
        "# Set this in your environment before running:\n",
        "# export GOOGLE_API_KEY=\"your_api_key_here\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
        "\n",
        "class BaseAgent:\n",
        "    \"\"\"Base class for all analysis agents.\"\"\"\n",
        "    def __init__(self, llm, retriever=None, focus_area: str=None):\n",
        "        self.llm = llm\n",
        "        self.retriever = retriever\n",
        "        self.focus_area = focus_area\n",
        "        if retriever and focus_area:\n",
        "            self.prompt_template = PromptTemplate(\n",
        "                template=generate_agent_prompt(focus_area),\n",
        "                input_variables=[\"context\", \"question\"]\n",
        "            )\n",
        "            self.qa_chain = RetrievalQA.from_chain_type(\n",
        "                llm=self.llm,\n",
        "                chain_type=\"stuff\",\n",
        "                retriever=self.retriever,\n",
        "                chain_type_kwargs={\"prompt\": self.prompt_template}\n",
        "            )\n",
        "\n",
        "    async def analyze(self, query: str) -> Dict:\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                result = await asyncio.to_thread(self.qa_chain.invoke, {\n",
        "                    \"query\": f\"Analyze the content focusing on {self.focus_area} for: {query}\"\n",
        "                })\n",
        "                return {\n",
        "                    \"focus_area\": self.focus_area,\n",
        "                    \"analysis\": result.get(\"result\", \"\"),\n",
        "                    \"error\": None\n",
        "                }\n",
        "            except Exception as e:\n",
        "                if \"429\" in str(e) and attempt < max_retries - 1:\n",
        "                    wait_time = 2 ** attempt * 30\n",
        "                    print(f\"Quota exceeded, retrying in {wait_time} seconds...\")\n",
        "                    await asyncio.sleep(wait_time)\n",
        "                else:\n",
        "                    return {\n",
        "                        \"focus_area\": self.focus_area,\n",
        "                        \"analysis\": \"\",\n",
        "                        \"error\": str(e)\n",
        "                    }\n",
        "\n",
        "class GapAgent(BaseAgent):\n",
        "    def __init__(self, llm, retriever):\n",
        "        super().__init__(llm, retriever, \"research gaps\")\n",
        "\n",
        "class ChallengeAgent(BaseAgent):\n",
        "    def __init__(self, llm, retriever):\n",
        "        super().__init__(llm, retriever, \"challenges\")\n",
        "\n",
        "class FutureWorkAgent(BaseAgent):\n",
        "    def __init__(self, llm, retriever):\n",
        "        super().__init__(llm, retriever, \"future work\")\n",
        "\n",
        "class LimitationAgent(BaseAgent):\n",
        "    def __init__(self, llm, retriever):\n",
        "        super().__init__(llm, retriever, \"limitations\")\n",
        "\n",
        "class SummaryAgent(BaseAgent):\n",
        "    def __init__(self, llm):\n",
        "        super().__init__(llm, None, \"summary\")\n",
        "\n",
        "    async def analyze(self, query: str, agent_results: List[Dict]) -> Dict:\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                agent_outputs = \"\\n\".join([\n",
        "                    f\"{result['focus_area'].title()}:\\n{result['analysis'] or 'No analysis available due to error: ' + result['error']}\"\n",
        "                    for result in agent_results\n",
        "                ])\n",
        "                prompt = generate_summary_prompt(query, agent_outputs)\n",
        "                response = await asyncio.to_thread(self.llm.invoke, [\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ])\n",
        "                summary = response.content if hasattr(response, 'content') else str(response)\n",
        "                return {\n",
        "                    \"focus_area\": self.focus_area,\n",
        "                    \"analysis\": summary,\n",
        "                    \"error\": None\n",
        "                }\n",
        "            except Exception as e:\n",
        "                if \"429\" in str(e) and attempt < max_retries - 1:\n",
        "                    wait_time = 2 ** attempt * 30\n",
        "                    print(f\"Quota exceeded for summary, retrying in {wait_time} seconds...\")\n",
        "                    await asyncio.sleep(wait_time)\n",
        "                else:\n",
        "                    return {\n",
        "                        \"focus_area\": self.focus_area,\n",
        "                        \"analysis\": \"\",\n",
        "                        \"error\": str(e)\n",
        "                    }\n",
        "\n",
        "class ResearchPaperAnalyzer:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.llm = ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-1.5-pro\",\n",
        "                temperature=0.5,\n",
        "                google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        "            )\n",
        "            self.embeddings = GoogleGenerativeAIEmbeddings(\n",
        "                model=\"models/embedding-001\",\n",
        "                google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing Google API: {e}\")\n",
        "            print(\"Ensure your GOOGLE_API_KEY is valid.\")\n",
        "            sys.exit(1)\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        self.vector_store = None\n",
        "\n",
        "    def search_papers(self, query: str, max_results: int = 10) -> List[Dict]:\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                client = arxiv.Client()\n",
        "                search = arxiv.Search(\n",
        "                    query=query,\n",
        "                    max_results=max_results,\n",
        "                    sort_by=arxiv.SortCriterion.Relevance\n",
        "                )\n",
        "                papers = [\n",
        "                    {\n",
        "                        'title': result.title,\n",
        "                        'authors': [author.name for author in result.authors],\n",
        "                        'summary': result.summary,\n",
        "                        'pdf_url': result.pdf_url,\n",
        "                        'published': result.published.strftime(\"%Y-%m-%d\")\n",
        "                    }\n",
        "                    for result in client.results(search)\n",
        "                ]\n",
        "                return papers\n",
        "            except Exception as e:\n",
        "                if attempt < max_retries - 1:\n",
        "                    wait_time = 2 ** attempt * 5\n",
        "                    print(f\"Error searching papers: {e}. Retrying in {wait_time} seconds...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"Failed to search papers after {max_retries} attempts: {e}\")\n",
        "                    return []\n",
        "\n",
        "    def create_vector_store(self, texts: List[str], metadatas: List[Dict] = None) -> Chroma:\n",
        "        if metadatas is None:\n",
        "            metadatas = [{} for _ in texts]\n",
        "        self.vector_store = Chroma.from_texts(\n",
        "            texts=texts,\n",
        "            metadatas=metadatas,\n",
        "            embedding=self.embeddings\n",
        "        )\n",
        "        return self.vector_store\n",
        "\n",
        "    async def analyze_content(self, query: str, content: str) -> Dict:\n",
        "        try:\n",
        "            chunks = self.text_splitter.split_text(content)\n",
        "            vector_store = self.create_vector_store(chunks)\n",
        "            retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "            agents = [\n",
        "                GapAgent(self.llm, retriever),\n",
        "                ChallengeAgent(self.llm, retriever),\n",
        "                FutureWorkAgent(self.llm, retriever),\n",
        "                LimitationAgent(self.llm, retriever)\n",
        "            ]\n",
        "\n",
        "            agent_tasks = [agent.analyze(query) for agent in agents]\n",
        "            agent_results = await asyncio.gather(*agent_tasks)\n",
        "\n",
        "            summary_agent = SummaryAgent(self.llm)\n",
        "            summary_result = await summary_agent.analyze(query, agent_results)\n",
        "\n",
        "            cleaned_text = clean_text(content)\n",
        "            pos_data = get_pos_tags(cleaned_text)\n",
        "            entities = extract_named_entities(cleaned_text)\n",
        "\n",
        "            return {\n",
        "                \"content\": content,\n",
        "                \"agent_analyses\": agent_results,\n",
        "                \"summary\": summary_result,\n",
        "                \"nlp_details\": {\n",
        "                    \"pos_tags\": pos_data,\n",
        "                    \"named_entities\": entities\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error during analysis: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    async def analyze_papers(self, query: str, papers: List[Dict]) -> Dict:\n",
        "        combined_text = \" \".join([paper['summary'] for paper in papers])\n",
        "        return await self.analyze_content(query, combined_text)\n",
        "\n",
        "def upload_pdf():\n",
        "    max_attempts = 3\n",
        "    for attempt in range(max_attempts):\n",
        "        print(\"Please upload a PDF of a research paper.\")\n",
        "        sys.stdout.flush()\n",
        "        try:\n",
        "            uploaded = files.upload()\n",
        "            for filename in uploaded.keys():\n",
        "                if filename.lower().endswith('.pdf'):\n",
        "                    return filename\n",
        "            print(\"No valid PDF file uploaded.\")\n",
        "            sys.stdout.flush()\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            if attempt < max_attempts - 1:\n",
        "                print(f\"Upload failed: {e}. Retrying in 5 seconds...\")\n",
        "                sys.stdout.flush()\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                print(f\"Failed to upload PDF after {max_attempts} attempts: {e}\")\n",
        "                sys.stdout.flush()\n",
        "                return None\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        texts = []\n",
        "        for img in images:\n",
        "            text = pytesseract.image_to_string(img)\n",
        "            if text.strip(): \n",
        "                texts.append(clean_text(text))\n",
        "        combined_text = \" \".join(texts)\n",
        "        if not combined_text.strip():\n",
        "            print(\"No text could be extracted from the PDF.\")\n",
        "            sys.stdout.flush()\n",
        "            return None\n",
        "        return combined_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "        sys.stdout.flush()\n",
        "        return None\n",
        "\n",
        "def get_user_input():\n",
        "    try:\n",
        "        print(\"\\nSelect input type: 1. Text, 2. PDF\")\n",
        "        sys.stdout.flush()\n",
        "        choice = input(\"Enter 1 or 2: \")\n",
        "        sys.stdout.flush()\n",
        "        if choice == '1':\n",
        "            print(\"Enter your query: \")\n",
        "            sys.stdout.flush()\n",
        "            query = input()\n",
        "            sys.stdout.flush()\n",
        "            return 'text', query\n",
        "        elif choice == '2':\n",
        "            pdf_path = upload_pdf()\n",
        "            if pdf_path:\n",
        "                text = extract_text_from_pdf(pdf_path)\n",
        "                if text:\n",
        "                    return 'pdf', text\n",
        "            return None, None\n",
        "        else:\n",
        "            print(\"Invalid choice\")\n",
        "            sys.stdout.flush()\n",
        "            return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting user input: {e}\")\n",
        "        sys.stdout.flush()\n",
        "        return None, None\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "        except ImportError:\n",
        "            print(\"This script must be run in Google Colab.\")\n",
        "            sys.stdout.flush()\n",
        "            return\n",
        "\n",
        "        analyzer = ResearchPaperAnalyzer()\n",
        "        print(\"Welcome to the Multimodal Research Paper Analyzer!\")\n",
        "        print(\"This tool supports text and PDF inputs.\\n\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        while True:\n",
        "            input_type, input_data = get_user_input()\n",
        "            if not input_type:\n",
        "                continue\n",
        "\n",
        "            if input_type == 'text':\n",
        "                print(\"\\nSearching for relevant papers...\")\n",
        "                sys.stdout.flush()\n",
        "                papers = analyzer.search_papers(input_data)\n",
        "                if not papers:\n",
        "                    print(\"No papers found for your query.\")\n",
        "                    sys.stdout.flush()\n",
        "                    continue\n",
        "                print(f\"Found {len(papers)} papers. Analyzing...\")\n",
        "                sys.stdout.flush()\n",
        "                results = await analyzer.analyze_papers(input_data, papers)\n",
        "            elif input_type == 'pdf':\n",
        "                print(\"\\nAnalyzing the uploaded research paper PDF...\")\n",
        "                sys.stdout.flush()\n",
        "                results = await analyzer.analyze_content(\"Analyze this paper\", input_data)\n",
        "\n",
        "            if \"error\" in results:\n",
        "                print(f\"Analysis failed: {results['error']}\")\n",
        "                sys.stdout.flush()\n",
        "                continue\n",
        "\n",
        "            print(\"\\n## Analysis Results\")\n",
        "            print(\"### Summary\")\n",
        "            sys.stdout.flush()\n",
        "            if results[\"summary\"][\"error\"]:\n",
        "                print(f\"Error: {results['summary']['error']}\")\n",
        "            else:\n",
        "                print(results[\"summary\"][\"analysis\"])\n",
        "            print()\n",
        "\n",
        "            print(\"### Agent Analyses\")\n",
        "            for analysis in results[\"agent_analyses\"]:\n",
        "                print(f\"#### {analysis['focus_area'].title()}\")\n",
        "                if analysis[\"error\"]:\n",
        "                    print(f\"Error: {analysis['error']}\")\n",
        "                else:\n",
        "                    print(analysis[\"analysis\"])\n",
        "                print()\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            print(\"### NLP Details\")\n",
        "            print(f\"**POS Tags**: {results['nlp_details']['pos_tags'][:10]}...\")\n",
        "            print(f\"**Named Entities**: {results['nlp_details']['named_entities'][:10]}...\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            output_file = f\"analysis_{uuid4().hex[:8]}.json\"\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"\\nResults saved to {output_file}\\n\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main loop: {e}\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "# Run the main function in Colab\n",
        "try:\n",
        "    import IPython\n",
        "    from IPython.display import display\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()  \n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())\n",
        "except ImportError:\n",
        "    # Fallback for non-Colab environments\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q2xmLMzcgAr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "034b0dc919df4f7cb046f148d7f367ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c166d072bac549af9a671d1727f06175",
              "IPY_MODEL_a646a9439bd34604a60f458a8220abf7",
              "IPY_MODEL_0d4002cd0cd5469aa6e48c151d82db9e"
            ],
            "layout": "IPY_MODEL_90c4963b468446f1ba41b97b46f5663c"
          }
        },
        "0d4002cd0cd5469aa6e48c151d82db9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d1900d3fda42b88d4a14bd4496da79",
            "placeholder": "​",
            "style": "IPY_MODEL_b294e6d1213f43788a043e9f77c1319b",
            "value": " 2/2 [01:04&lt;00:00, 30.16s/it]"
          }
        },
        "6954435b1acf455f9a60a8adfba333e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90c4963b468446f1ba41b97b46f5663c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a646a9439bd34604a60f458a8220abf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50f7118303145bea7f13a4a30b8d302",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd1e4183fe84006a2f0f1ff7278581f",
            "value": 2
          }
        },
        "b294e6d1213f43788a043e9f77c1319b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b50f7118303145bea7f13a4a30b8d302": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c166d072bac549af9a671d1727f06175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff792a0b55e64ea0b5b91c618bed4bc8",
            "placeholder": "​",
            "style": "IPY_MODEL_6954435b1acf455f9a60a8adfba333e0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ecd1e4183fe84006a2f0f1ff7278581f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8d1900d3fda42b88d4a14bd4496da79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff792a0b55e64ea0b5b91c618bed4bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
